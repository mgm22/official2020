{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "colab": {
      "name": "ai504_03_pytorch.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mgm22/official2020/blob/master/ai504_03_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5E0jL5f16urz",
        "colab_type": "text"
      },
      "source": [
        "![picture](https://drive.google.com/uc?id=1vC0N3Obk4HZJk9JOG7fKgYE10YYlCqsg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDPkRiex6ur0",
        "colab_type": "text"
      },
      "source": [
        "# Week 3: PyTorch, Logistic Regression and MLP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUOTG8cw6ur1",
        "colab_type": "text"
      },
      "source": [
        "- We will cover basic concepts of PyTorch Framework (tensor operations, GPU utilizing and autograd)\n",
        "- We will implement simple logistic regression and multinomial logistic regression (softmax) with PyTorch\n",
        "- We will use simple linear model and multi-layer perceptron (MLP) in this class\n",
        "\n",
        "If you have any questions, feel free to ask\n",
        "- For additional questions, post questions in classum or send emails to jihoontack@kaist.ac.kr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2DE_Sli6ur3",
        "colab_type": "text"
      },
      "source": [
        "## Why PyTorch?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKL_2ASP6ur4",
        "colab_type": "text"
      },
      "source": [
        "- Intuitive and concise code\n",
        "- Define by Run method (Tensorflow is Define and Run method)\n",
        "- High compatibility with Numpy (almost one-to-one mapping)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDM6yUCQ6ur5",
        "colab_type": "text"
      },
      "source": [
        "![picture](https://drive.google.com/uc?id=1nAfTkF8Kp4YEI1pBeShs3L7NCPHx_iHQ)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45MCIjXO6ur6",
        "colab_type": "text"
      },
      "source": [
        "## 0. Prelim: Load packages & GPU setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSoLeQJ76ur9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "4fba3454-6541-4de3-8d21-cfbc930553c4"
      },
      "source": [
        "# visualize current GPU usages in your server\n",
        "!nvidia-smi "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Sep 16 10:34:09 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.66       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   32C    P8    27W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFaCVYwV6usD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set gpu by number \n",
        "import os\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'  # setting gpu number"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uG6tZMea6usJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load packages\n",
        "import torch\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAwikhhN6usN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "97522bce-8dc1-4b65-cdce-613b29abbf53"
      },
      "source": [
        "# print the version of PyTorch\n",
        "print(torch.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.6.0+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V78Qv0RP6usR",
        "colab_type": "text"
      },
      "source": [
        "## 1. PyTorch and Numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBHpHX1U6usS",
        "colab_type": "text"
      },
      "source": [
        "PyTorch use **tensor**: the basic data structure in PyTorch.\\\n",
        "**Tensor: n-dimensional array + GPU calculation is supported**\\\n",
        "**Almost the same with Numpy array**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQcMdZHH6usT",
        "colab_type": "text"
      },
      "source": [
        "![picture](https://drive.google.com/uc?id=1z2v05mGyhP_FpEa3Z4JsNpgbtEnkg0bo)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wiRZJ9V66usU",
        "colab_type": "text"
      },
      "source": [
        "### PyTorch and Numpy shares almost identical grammer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_sqOZIS6usV",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "**We will show some examples of:**\n",
        "- Same operation with identical grammer\n",
        "- Same operation with different grammer\n",
        "- Different operation with same grammer\n",
        "\n",
        "**We will not handle all examples in this class :(**\n",
        "- For more examples, see the following reference: https://github.com/wkentaro/pytorch-for-numpy-users"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVy43zVb6usW",
        "colab_type": "text"
      },
      "source": [
        "**First! Define Numpy array and PyTorch tensor**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyjIN_bV6usd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "d3260b6a-cdae-486f-85bb-9f46beaa9a8d"
      },
      "source": [
        "np_array_1 = np.array([1, 2, 3, 4])\n",
        "np_array_2 = np.array([5, 6, 7, 8])\n",
        "torch_tensor_1 = torch.tensor([1, 2, 3, 4])\n",
        "torch_tensor_2 = torch.tensor([5 ,6 ,7, 8])\n",
        "\n",
        "print (np_array_1)\n",
        "print (np_array_2)\n",
        "print (torch_tensor_1)\n",
        "print (torch_tensor_2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 2 3 4]\n",
            "[5 6 7 8]\n",
            "tensor([1, 2, 3, 4])\n",
            "tensor([5, 6, 7, 8])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzE11VQt6usg",
        "colab_type": "text"
      },
      "source": [
        "**1) Same operations with identical grammer**\n",
        "\n",
        "Example) Get the shape of the tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoQmUXwb6usg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "2d77a807-9ac3-4a5f-8876-5741293437f1"
      },
      "source": [
        "# numpy\n",
        "print (np_array_1.shape)\n",
        "\n",
        "# torch\n",
        "print (torch_tensor_1.shape)\n",
        "print (torch_tensor_1.size()) # size() and shape operation is identical in torch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4,)\n",
            "torch.Size([4])\n",
            "torch.Size([4])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhxQveiC6usk",
        "colab_type": "text"
      },
      "source": [
        "**2) Same operations with different grammer**\n",
        "\n",
        "Example 1) Concatenate two tensors\n",
        "- numpy use `np.concatenate`\n",
        "- torch use `torch.cat`\n",
        "- IMPORTANT: axis (numpy) and dim (torch) is identical"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdYZUdct6usl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "571a69d5-06a6-4126-8b17-8cdbdd2ba00e"
      },
      "source": [
        "# numpy\n",
        "np_concate = np.concatenate([np_array_1, np_array_2], axis=0)\n",
        "print ('----numpy----')\n",
        "print (np_concate)\n",
        "\n",
        "# torch\n",
        "torch_concate= torch.cat([torch_tensor_1, torch_tensor_2], dim=0)\n",
        "print ('----torch----')\n",
        "print (torch_concate)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----numpy----\n",
            "[1 2 3 4 5 6 7 8]\n",
            "----torch----\n",
            "tensor([1, 2, 3, 4, 5, 6, 7, 8])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Jo0SMSK6usp",
        "colab_type": "text"
      },
      "source": [
        "Example 2) reshape the tensor shape\n",
        "- numpy use `X.reshape`\n",
        "- torch use `X.view`\n",
        "- IMPORTANT: axis (numpy) and dim (torch) is identical"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETbbtoS06usq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "e8c70146-c21d-4eaf-9549-fd7e212f0c2e"
      },
      "source": [
        "# numpy\n",
        "np_reshaped = np_concate.reshape(4, 2)\n",
        "print ('----numpy----')\n",
        "print (np_reshaped)\n",
        "print (np_reshaped.shape)\n",
        "\n",
        "# torch\n",
        "torch_reshaped = torch_concate.view(4, 2)\n",
        "print ('----torch----')\n",
        "print (torch_reshaped)\n",
        "print (torch_reshaped.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----numpy----\n",
            "[[1 2]\n",
            " [3 4]\n",
            " [5 6]\n",
            " [7 8]]\n",
            "(4, 2)\n",
            "----torch----\n",
            "tensor([[1, 2],\n",
            "        [3, 4],\n",
            "        [5, 6],\n",
            "        [7, 8]])\n",
            "torch.Size([4, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BV0IHa06ust",
        "colab_type": "text"
      },
      "source": [
        "**3) Different operations with same grammer (Confusing operations)**\n",
        "\n",
        "Example) manipulation tensors\n",
        "- Same grammer `repeat`  has different operations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nvXTcai6ust",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 149
        },
        "outputId": "23df6982-6d35-442c-b2dd-9f7af3fbe35c"
      },
      "source": [
        "x = np.array([1, 2, 3])\n",
        "x_repeat = x.repeat(2)\n",
        "\n",
        "print ('----numpy----')\n",
        "print (x)\n",
        "print (x_repeat)\n",
        "\n",
        "x = torch.tensor([1, 2, 3])\n",
        "x_repeat = x.repeat(2)\n",
        "\n",
        "print ('----torch----')\n",
        "print (x)\n",
        "print (x_repeat)\n",
        "\n",
        "# To obtain the same result with np.repeat (will skip explanation: you should be proficient with reshaping operations)\n",
        "x_repeat = x.view(3, 1).repeat(1, 2).view(-1)\n",
        "print (x_repeat)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----numpy----\n",
            "[1 2 3]\n",
            "[1 1 2 2 3 3]\n",
            "----torch----\n",
            "tensor([1, 2, 3])\n",
            "tensor([1, 2, 3, 1, 2, 3])\n",
            "tensor([1, 1, 2, 2, 3, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaDi0HoM6usx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "59d0d090-b52b-4621-ca9f-93df7c226245"
      },
      "source": [
        "# similar manipulation operation: stack & repeat\n",
        "x = torch.tensor([1, 2, 3])\n",
        "x_repeat = x.repeat(4)\n",
        "x_stack = torch.stack([x, x, x, x])\n",
        "\n",
        "print (x_repeat)\n",
        "print (x_stack)\n",
        "print (x_repeat.view(4, 3)) # reshape x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3])\n",
            "tensor([[1, 2, 3],\n",
            "        [1, 2, 3],\n",
            "        [1, 2, 3],\n",
            "        [1, 2, 3]])\n",
            "tensor([[1, 2, 3],\n",
            "        [1, 2, 3],\n",
            "        [1, 2, 3],\n",
            "        [1, 2, 3]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ur4APnU96us0",
        "colab_type": "text"
      },
      "source": [
        "## 2. Tensor operations under GPU utilization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewUVnXlB6us2",
        "colab_type": "text"
      },
      "source": [
        "Deep learning frameworks utilize GPUs to accelarate computations.\n",
        "\n",
        "In this section, we will learn **how to utilize GPU** in PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVEjX0gC6us2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "b8e00faa-66cb-47f3-ac4f-f2d288b2b16c"
      },
      "source": [
        "print(torch.cuda.is_available())  # Is GPU accessible?"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTygIE2U6us5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = torch.ones(3)\n",
        "b = torch.randn(100, 50, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQvtkcty6us9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "cb503345-14f5-4c5e-e4bb-26ffe4c1e342"
      },
      "source": [
        "print(a.device)\n",
        "print(b.device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpu\n",
            "cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uihMYdDO6us_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "c = a + b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3tA6rk_6utD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "96b47d59-dece-4bfd-9a0c-3fc67125dddc"
      },
      "source": [
        "print(c.device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wgw4BPsD6utF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# upload a and b to GPU\n",
        "a = a.to('cuda')\n",
        "b = b.to('cuda')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlrDGGwX6utI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "b097ebe9-529b-45ac-c46f-64ebfa4f2edc"
      },
      "source": [
        "print(a.device)\n",
        "print(b.device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n",
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yU6jb_Cw6utK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "c = a + b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EL1aRhEq6utN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "e7086cc3-4bcc-4b5d-8f03-7220607ed57b"
      },
      "source": [
        "print(c.device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYil2fvo6utQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "c = c.to('cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSUiHkGS6utS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "6e92d624-7a4b-48b1-b368-fb03cb69d86d"
      },
      "source": [
        "print(c.device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsw2SgFt6utW",
        "colab_type": "text"
      },
      "source": [
        "## 3. Autograd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTJ7aEZv6utW",
        "colab_type": "text"
      },
      "source": [
        "Central to all neural networks in PyTorch is the `autograd` package. \n",
        "\n",
        "The `autograd` package provides automatic differentiation for all operations on Tensors. \n",
        "\n",
        "`torch.Tensor` is the central class of the package. If you set its attribute `.requires_grad` as True, it starts to track all operations on it. When you finish your computation you can call `.backward()` and have all the gradients computed automatically. The gradient for this tensor will be accumulated into `.grad` attribute.\n",
        "\n",
        "To stop a tensor from tracking history, you can call `.detach()` to detach it from the computation history, and to prevent future computation from being tracked."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cB_bXgrg6utY",
        "colab_type": "text"
      },
      "source": [
        "### Example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pviKWj96utZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "6514e44c-ea78-4590-db4e-9d1fa2c7e40a"
      },
      "source": [
        "x = torch.ones(2, 2, requires_grad=True)\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.]], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUzvkW-c6utb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "4874724a-9c19-4387-b61f-5411cc0dfc13"
      },
      "source": [
        "y = x + 2\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[3., 3.],\n",
            "        [3., 3.]], grad_fn=<AddBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxUp5eKT6utd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "d5f9f1c8-c632-42d6-b9dc-8344d986e96f"
      },
      "source": [
        "z = y * y * 3\n",
        "print(z)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[27., 27.],\n",
            "        [27., 27.]], grad_fn=<MulBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HhP24Bn6uth",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "bce1cb95-7dfd-4def-f3f1-12fbc8dc7a86"
      },
      "source": [
        "out = z.mean()\n",
        "print(out)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(27., grad_fn=<MeanBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-PSWKSS6utj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y.retain_grad()\n",
        "z.retain_grad()\n",
        "out.backward()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4MJafST6utm",
        "colab_type": "text"
      },
      "source": [
        "![picture](https://drive.google.com/uc?id=1JyMWTbaU6ktJAHx2XqiU7s4tId-cxiLF)\n",
        "![picture](https://drive.google.com/uc?id=17j-aNqj1yjZfVPCKZJRt6YVZ-7usf5PH)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKhbWBs16utm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "376b2c61-086e-45f0-82ed-8d10e63fb070"
      },
      "source": [
        "print(z.grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.2500, 0.2500],\n",
            "        [0.2500, 0.2500]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QxBANoZ6uto",
        "colab_type": "text"
      },
      "source": [
        "![picture](https://drive.google.com/uc?id=1jPfdq6piSkkwZ21nX7kIBa-xGJE6uPBu)\n",
        "![picture](https://drive.google.com/uc?id=1NN0kpdvRRP9NwguXJHnU3u8VikMFUKw2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YG-w-fVF6utp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "1a9a1a9b-6d2e-4d2e-9768-0a598bdd9c1d"
      },
      "source": [
        "print(y.grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[4.5000, 4.5000],\n",
            "        [4.5000, 4.5000]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fr94jX_C6utr",
        "colab_type": "text"
      },
      "source": [
        "![picture](https://drive.google.com/uc?id=1HllHu2CxuNFX8mc6QdQEEtnXJ3Rvo6TE)\n",
        "![picture](https://drive.google.com/uc?id=1jWJPOXVLG6mdUyDSklocNWPVa9Rg62K3)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVEak3pi6utr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "e6b8f53a-2a51-4b0e-e6c4-c2864c3b67d0"
      },
      "source": [
        "print(x.grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[4.5000, 4.5000],\n",
            "        [4.5000, 4.5000]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHmF47Tg6utt",
        "colab_type": "text"
      },
      "source": [
        "### Efficient inference (testing) with torch.no_grad()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSutPo096utu",
        "colab_type": "text"
      },
      "source": [
        "To prevent tracking history (and using memory), you can also wrap the code block in with `torch.no_grad()`\n",
        "\n",
        "Situation: when **gradient calculation is not required** e.g., inference\\\n",
        "Solution: use `torch.no_grad()`, then torch doesn't generate computational graph for back propagation, therefore it is **much faster**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5Ur0o5M6utv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with torch.no_grad():\n",
        "    x = torch.ones(2, 2, requires_grad=True)\n",
        "    y = x + 2\n",
        "    z = y * y * 3\n",
        "    out = z.mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c12JF0Xb6uty",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "75f0bba3-6c46-4f96-f7d3-5cb72b4dd4bf"
      },
      "source": [
        "out"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(27.)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Shns5QmS6utz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "outputId": "ddba6302-ab90-4c6a-c10d-8820fbf066c1"
      },
      "source": [
        "out.backward() ## ERROR!!!!: we used torch.no_grad()!!"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-bf3332dd1f01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m## ERROR!!!!: we used torch.no_grad()!!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    125\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2RKENrt6ut1",
        "colab_type": "text"
      },
      "source": [
        "## 4. nn.Module"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xq3NEIRw6ut2",
        "colab_type": "text"
      },
      "source": [
        "![picture](https://drive.google.com/uc?id=1Vu3oRATA-EWDycO2zVWkBdzndU-8C5cB)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvDIGC2C6ut2",
        "colab_type": "text"
      },
      "source": [
        "### Using pre-defined modules (subset of models) in PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEg8uyZX6ut2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "856cfd92-46d5-4524-cd4d-c223afcd3177"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "X = torch.tensor([[1., 2., 3.], [4., 5., 6.]])\n",
        "\n",
        "print (X)\n",
        "print (X.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]])\n",
            "torch.Size([2, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3U1QXNP6ut4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# input dim 3, output dim 1\n",
        "linear_fn = nn.Linear(3, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvI2tJqK6ut7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "020e43ce-6873-410c-8927-3439c6d12ce6"
      },
      "source": [
        "linear_fn  # WX + b"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=3, out_features=1, bias=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcSB2G8E6ut9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "8602b8dd-f9f1-4ee2-8f92-9ea4405194c3"
      },
      "source": [
        "Y = linear_fn(X)\n",
        "print(Y)\n",
        "print(Y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-1.7332],\n",
            "        [-4.9038]], grad_fn=<AddmmBackward>)\n",
            "torch.Size([2, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGYrBMVz6ut_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "fc0c8d49-71c1-4be5-c53b-9b9c80fa17c5"
      },
      "source": [
        "Y = Y.sum()\n",
        "print(Y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(-6.6369, grad_fn=<SumBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Cq6r3E76uuB",
        "colab_type": "text"
      },
      "source": [
        "You can use other types of `nn.Module` in PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6ZhabUe6uuB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nn.Conv2d\n",
        "nn.RNNCell\n",
        "nn.LSTMCell\n",
        "nn.GRUCell\n",
        "nn.Transformer;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72PcjVfT6uuC",
        "colab_type": "text"
      },
      "source": [
        "### How can we design a customized model (neural network)?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEMNpOdM6uuD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, hidden_dim):\n",
        "        super(Model, self).__init__()\n",
        "        self.linear_1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.linear_2 = nn.Linear(hidden_dim, output_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "    def forward(self, x):\n",
        "        x = self.linear_1(x)\n",
        "        x = self.relu(x) # Activation function\n",
        "        x = self.linear_2(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G61s4j-M6uuG",
        "colab_type": "text"
      },
      "source": [
        "**What is activation function?**\n",
        "- They make non-linearity for deep neural networks\n",
        "- Therefore, deep neural networks can approximate complex functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IU0Bo9786uuH",
        "colab_type": "text"
      },
      "source": [
        "![picture](https://drive.google.com/uc?id=1dxJJUOzYykRfW2q3my2Qtg82RsjptIx4)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsT7m3sa6uuH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nn.Sigmoid\n",
        "nn.ReLU\n",
        "nn.LeakyReLU\n",
        "nn.Tanh;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t75G71-s6uuK",
        "colab_type": "text"
      },
      "source": [
        "## 5. MNIST classification with PyTorch (Logistic regression & MLP)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G31nO5D_6uuK",
        "colab_type": "text"
      },
      "source": [
        "![picture](https://drive.google.com/uc?id=1kdig6RLSCvYJNqarbb8gviYsnxZfSkYQ)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CI0HWocl6uuK",
        "colab_type": "text"
      },
      "source": [
        "### What is MNIST & How to do multi-class classification?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qdo4sH-y6uuL",
        "colab_type": "text"
      },
      "source": [
        "The MNIST database of **handwritten digits from 0 to 9**, has a training set of 60,000 examples, and a test set of 10,000 examples.\n",
        "\n",
        "Since we have 10 classes (0~9), current problem can be interpreted as **multinomial logistic regression** (**multi-class classification**).\n",
        "\n",
        "Therefore, we use **softmax** function to handle multiple class output with **cross-entropy** loss function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGKn_Eif6uuL",
        "colab_type": "text"
      },
      "source": [
        "![picture](https://drive.google.com/uc?id=1v-QvM2MEMku6wWMb_8f8NIqIDzby7wJP)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgVMHwjs6uuL",
        "colab_type": "text"
      },
      "source": [
        "### Load packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZe3XhdR6uuM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScCFMO3Z6uuT",
        "colab_type": "text"
      },
      "source": [
        "### Load datasets for training & testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VeBKjAyU6uuU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# MNIST dataset \n",
        "train_dataset = torchvision.datasets.MNIST(root='./', train=True, transform=transforms.ToTensor(), download=True)\n",
        "test_dataset = torchvision.datasets.MNIST(root='./', train=False, transform=transforms.ToTensor())\n",
        "\n",
        "# Data loader\n",
        "# mini batch size\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=128, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=100, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MATjOXo-LU4W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "outputId": "a9ba023f-b937-4227-de6a-133061552f9a"
      },
      "source": [
        "train_dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 60000\n",
              "    Root location: ./\n",
              "    Split: Train\n",
              "    StandardTransform\n",
              "Transform: ToTensor()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZECNRy86uuX",
        "colab_type": "text"
      },
      "source": [
        "### Define model (we will use one layer classifier first)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93kseLrF6uuX",
        "colab_type": "text"
      },
      "source": [
        "![picture](https://drive.google.com/uc?id=1Xe4J88NglbuASnfYJYI7ISqA1c1rcs5P)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZxdVXDC6uuY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define model class\n",
        "# This model has one hidden layer\n",
        "class Multinomial_logistic_regression(nn.Module):\n",
        "    def __init__(self, input_size, output_size):\n",
        "        super(Multinomial_logistic_regression, self).__init__()\n",
        "        self.fc = nn.Linear(input_size, output_size) \n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.fc(x)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYw2earF6uua",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generate model\n",
        "model = Multinomial_logistic_regression(784, 10)  # init(784, 10)\n",
        "# input dim: 784  / output dim: 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-dclB2Q6uub",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "1b19a5d5-5b9c-4282-d848-2ccc57413bf8"
      },
      "source": [
        "model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Multinomial_logistic_regression(\n",
              "  (fc): Linear(in_features=784, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NF-WrNZy6uud",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Upload model to GPU\n",
        "model = model.to('cuda')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUsuPoRr6uuf",
        "colab_type": "text"
      },
      "source": [
        "### Define optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwtY2BoD6uug",
        "colab_type": "text"
      },
      "source": [
        "Optimization is about finding the best solution (model parameter) that fits the given dataset!\n",
        "\n",
        "PyTorch optimizer is about **which optimization methods to use for training**\n",
        "\n",
        "We will not handle the details in this class. (take **\"Optimization for AI (AI505)\"** course)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4QxQVC36uug",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Optimizer define\n",
        "# optimizer = torch.optim.SGD(model.parameters(), lr=0.05) \n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.05, momentum=0.9)\n",
        "# toptimizer = orch.optim.Adam(model.parameters(), lr=0.05)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qu25X6b96uui",
        "colab_type": "text"
      },
      "source": [
        "![picture](https://drive.google.com/uc?id=1BvkB6O1hsGZ4YkD92k-E3I59omprN7qz)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dSzbVMx6uuj",
        "colab_type": "text"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wm20A8l56uuj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 772
        },
        "outputId": "1da1ecd3-4bf4-4ee9-9f17-cc6b24b09734"
      },
      "source": [
        "# Loss function define (we use cross-entropy)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "#Train the model\n",
        "total_step = len(train_loader)\n",
        "\n",
        "for epoch in range(10):\n",
        "    for i, (images, labels) in enumerate(train_loader):  # mini batch for loop\n",
        "        # upload to gpu\n",
        "        images = images.reshape(-1, 28*28).to('cuda')\n",
        "        labels = labels.to('cuda')\n",
        "        \n",
        "        #print (images.shape)\n",
        "        \n",
        "        # Forward\n",
        "        outputs = model(images)  # forwardI(images): get prediction\n",
        "        loss = loss_fn(outputs, labels)  # calculate the loss (crossentropy loss) with ground truth & prediction value\n",
        "        \n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()  # automatic gradient calculation (autograd)\n",
        "        optimizer.step()  # update model parameter with requires_grad=True \n",
        "        \n",
        "        if (i+1) % 100 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
        "                   .format(epoch+1, 10, i+1, total_step, loss.item()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [100/469], Loss: 0.3161\n",
            "Epoch [1/10], Step [200/469], Loss: 0.5717\n",
            "Epoch [1/10], Step [300/469], Loss: 0.4693\n",
            "Epoch [1/10], Step [400/469], Loss: 0.3231\n",
            "Epoch [2/10], Step [100/469], Loss: 0.3283\n",
            "Epoch [2/10], Step [200/469], Loss: 0.3374\n",
            "Epoch [2/10], Step [300/469], Loss: 0.3601\n",
            "Epoch [2/10], Step [400/469], Loss: 0.3214\n",
            "Epoch [3/10], Step [100/469], Loss: 0.2335\n",
            "Epoch [3/10], Step [200/469], Loss: 0.3894\n",
            "Epoch [3/10], Step [300/469], Loss: 0.1610\n",
            "Epoch [3/10], Step [400/469], Loss: 0.2714\n",
            "Epoch [4/10], Step [100/469], Loss: 0.1969\n",
            "Epoch [4/10], Step [200/469], Loss: 0.2174\n",
            "Epoch [4/10], Step [300/469], Loss: 0.2992\n",
            "Epoch [4/10], Step [400/469], Loss: 0.0796\n",
            "Epoch [5/10], Step [100/469], Loss: 0.2854\n",
            "Epoch [5/10], Step [200/469], Loss: 0.2289\n",
            "Epoch [5/10], Step [300/469], Loss: 0.1865\n",
            "Epoch [5/10], Step [400/469], Loss: 0.3938\n",
            "Epoch [6/10], Step [100/469], Loss: 0.2822\n",
            "Epoch [6/10], Step [200/469], Loss: 0.1470\n",
            "Epoch [6/10], Step [300/469], Loss: 0.2263\n",
            "Epoch [6/10], Step [400/469], Loss: 0.1761\n",
            "Epoch [7/10], Step [100/469], Loss: 0.1949\n",
            "Epoch [7/10], Step [200/469], Loss: 0.2140\n",
            "Epoch [7/10], Step [300/469], Loss: 0.1596\n",
            "Epoch [7/10], Step [400/469], Loss: 0.2255\n",
            "Epoch [8/10], Step [100/469], Loss: 0.3253\n",
            "Epoch [8/10], Step [200/469], Loss: 0.2976\n",
            "Epoch [8/10], Step [300/469], Loss: 0.3035\n",
            "Epoch [8/10], Step [400/469], Loss: 0.2966\n",
            "Epoch [9/10], Step [100/469], Loss: 0.3053\n",
            "Epoch [9/10], Step [200/469], Loss: 0.3061\n",
            "Epoch [9/10], Step [300/469], Loss: 0.2975\n",
            "Epoch [9/10], Step [400/469], Loss: 0.2456\n",
            "Epoch [10/10], Step [100/469], Loss: 0.2094\n",
            "Epoch [10/10], Step [200/469], Loss: 0.1912\n",
            "Epoch [10/10], Step [300/469], Loss: 0.3680\n",
            "Epoch [10/10], Step [400/469], Loss: 0.2593\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dez9185J6uul",
        "colab_type": "text"
      },
      "source": [
        "### Test the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aC6RuTOI6uul",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "e649694a-04bc-4f48-eea3-af0cd3f93875"
      },
      "source": [
        "# Test the model\n",
        "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.reshape(-1, 28*28).to('cuda')\n",
        "        labels = labels.to('cuda')\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)  # classificatoin model -> get the label prediction of top 1 \n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 92.38 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XupMl9of6uun",
        "colab_type": "text"
      },
      "source": [
        "### New model: MLP (multi-layer-perceptron)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udqa85TL6uun",
        "colab_type": "text"
      },
      "source": [
        "Previous model used multinomial logistic regression (one linear layer)\\\n",
        "What if we use **MLP (multi-layer-perceptron)?** A neural network with hidden layers?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3IuKfbd6uun",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# New model with multi layer\n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size) \n",
        "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
        "        self.sigmoid = nn.Sigmoid()  # sigmoid activation function (you can customize)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.sigmoid(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.sigmoid(out)\n",
        "        out = self.fc3(out)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXqWsc1N6uuq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 772
        },
        "outputId": "c410666d-7f79-4bfa-dc8d-23732d347a6d"
      },
      "source": [
        "# Generate model\n",
        "model = NeuralNet(784, 20, 10)  # init(784, 20, 10)\n",
        "# input dim: 784  / hidden dim: 20  / output dim: 10\n",
        "\n",
        "# Upload model to GPU\n",
        "model = model.to('cuda')\n",
        "\n",
        "# Loss function define (we use cross-entropy)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "# Define optimizer\n",
        "# optimizer = torch.optim.SGD(model.parameters(), lr=0.05) \n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.05, momentum=0.9)\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=0.05)\n",
        "\n",
        "# Train the model\n",
        "total_step = len(train_loader)\n",
        "\n",
        "for epoch in range(10):\n",
        "    for i, (images, labels) in enumerate(train_loader):  # mini batch for loop\n",
        "        # upload to gpu\n",
        "        images = images.reshape(-1, 28*28).to('cuda')\n",
        "        labels = labels.to('cuda')\n",
        "        \n",
        "        # Forward\n",
        "        outputs = model(images)  # forwardI(images): get prediction\n",
        "        loss = loss_fn(outputs, labels)  # calculate the loss (crossentropy loss) with ground truth & prediction value\n",
        "        \n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()  # automatic gradient calculation (autograd)\n",
        "        optimizer.step()  # update model parameter with requires_grad=True \n",
        "        \n",
        "        if (i+1) % 100 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
        "                   .format(epoch+1, 10, i+1, total_step, loss.item()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Step [100/469], Loss: 2.2542\n",
            "Epoch [1/10], Step [200/469], Loss: 1.8349\n",
            "Epoch [1/10], Step [300/469], Loss: 1.3046\n",
            "Epoch [1/10], Step [400/469], Loss: 0.7962\n",
            "Epoch [2/10], Step [100/469], Loss: 0.5215\n",
            "Epoch [2/10], Step [200/469], Loss: 0.4933\n",
            "Epoch [2/10], Step [300/469], Loss: 0.3579\n",
            "Epoch [2/10], Step [400/469], Loss: 0.3483\n",
            "Epoch [3/10], Step [100/469], Loss: 0.4749\n",
            "Epoch [3/10], Step [200/469], Loss: 0.2293\n",
            "Epoch [3/10], Step [300/469], Loss: 0.4201\n",
            "Epoch [3/10], Step [400/469], Loss: 0.2290\n",
            "Epoch [4/10], Step [100/469], Loss: 0.1759\n",
            "Epoch [4/10], Step [200/469], Loss: 0.2560\n",
            "Epoch [4/10], Step [300/469], Loss: 0.2464\n",
            "Epoch [4/10], Step [400/469], Loss: 0.2843\n",
            "Epoch [5/10], Step [100/469], Loss: 0.1674\n",
            "Epoch [5/10], Step [200/469], Loss: 0.1820\n",
            "Epoch [5/10], Step [300/469], Loss: 0.1773\n",
            "Epoch [5/10], Step [400/469], Loss: 0.2259\n",
            "Epoch [6/10], Step [100/469], Loss: 0.2029\n",
            "Epoch [6/10], Step [200/469], Loss: 0.2418\n",
            "Epoch [6/10], Step [300/469], Loss: 0.2652\n",
            "Epoch [6/10], Step [400/469], Loss: 0.1565\n",
            "Epoch [7/10], Step [100/469], Loss: 0.1960\n",
            "Epoch [7/10], Step [200/469], Loss: 0.1195\n",
            "Epoch [7/10], Step [300/469], Loss: 0.0883\n",
            "Epoch [7/10], Step [400/469], Loss: 0.1231\n",
            "Epoch [8/10], Step [100/469], Loss: 0.1182\n",
            "Epoch [8/10], Step [200/469], Loss: 0.1484\n",
            "Epoch [8/10], Step [300/469], Loss: 0.1712\n",
            "Epoch [8/10], Step [400/469], Loss: 0.1581\n",
            "Epoch [9/10], Step [100/469], Loss: 0.2196\n",
            "Epoch [9/10], Step [200/469], Loss: 0.0885\n",
            "Epoch [9/10], Step [300/469], Loss: 0.1765\n",
            "Epoch [9/10], Step [400/469], Loss: 0.1725\n",
            "Epoch [10/10], Step [100/469], Loss: 0.1491\n",
            "Epoch [10/10], Step [200/469], Loss: 0.1347\n",
            "Epoch [10/10], Step [300/469], Loss: 0.2211\n",
            "Epoch [10/10], Step [400/469], Loss: 0.1568\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cL_eh4Wr6uus",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "3d9d1bc9-6c32-493f-d59c-cf40f3f51578"
      },
      "source": [
        "# Test the model\n",
        "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.reshape(-1, 28*28).to('cuda')\n",
        "        labels = labels.to('cuda')\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)  # classificatoin model -> get the label prediction of top 1 \n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 95.07 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cY-9p0XN6uut",
        "colab_type": "text"
      },
      "source": [
        "### Change the following options to obtain better accuracy!! (try it by your-self)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXqlruOH6uut",
        "colab_type": "text"
      },
      "source": [
        "#### (1) Model configurations: \n",
        "- size of hidden layer units\n",
        "- number of layers\n",
        "- type of activation function (e.g., relu, tanh, softplus etc.)\n",
        "\n",
        "#### (2) Optimization configurations\n",
        "- learning rate\n",
        "- epoch\n",
        "- type of optimizer\n",
        "- momentem hyperparameter"
      ]
    }
  ]
}